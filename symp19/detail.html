<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">

        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <title>SoCal NLP Symposium 2019</title>
        <meta name="description" content="Welcome to the Southern California Natural Language Processing Symposium 2019!">
        <meta name="keywords" content="SoCal,NLP,Symposium,Southern California,Natural Language Processing,Machine Learning,Deep Learning">
        <meta name="author" content="SoCal NLP Symposium Organizers">

        <link rel="icon" href="static/favicon.ico">

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <link rel="stylesheet" href="css/fonts.css">
        <link rel="stylesheet" href="css/custom.css">
    </head>

    <body>
        <div id="header">
            <div id="header-desc">
                <p style="font-size:2rem;">SoCal NLP Symposium 2019</p>
                <p style="font-size:1.5rem;">University of Southern California</p>
            </div>
        </div>

        <div class="container">
            <nav class="navbar navbar-expand-lg navbar-light bg-light rounded">
                <a class="navbar-brand"><b>Invited Talk Details</b></a>
                <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#content" aria-controls="navbarsExample09" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>
            </nav>
        </div>

        <br/>

        <div id="anima" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Anima Anandkumar</h4>
                    <hr>
                    <!--<h5></h5>-->
                    <!--<p>-->
                    <!--</p>-->
                    <h5>Biography</h5>
                    <p>
                    Anima Anandkumar is a Bren Professor of Computing and Mathematical Sciences at the California Institute of Technology and Director of Research in Machine Learning at NVIDIA. Her research is in the areas of large-scale machine learning and high-dimensional statistics, and in particular, development of tensor methods that scale up machine learning to higher dimensions. She is also the recipient of the Alfred Sloan Fellowship, Microsoft Faculty Fellowship, ARO and AFOSR Young Investigator Awards, NSF Career Award and several paper awards. She received her B.Tech in Electrical Engineering from IIT Madras in 2004 and her PhD from Cornell University in 2009. She was a Postdoctoral Researcher in the Stochastic Systems Group at MIT from 2009-2010, an Assistant Professor at UC Irvine from 2010-2016, and Principal Scientist at Amazon Web Services from 2016-2018.
                    </p>
                </div>
            </div>
        </div>

        <br/>

        <div id="marjan" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Marjan Ghazvininejad</h4>
                    <hr>
                    <!--<h5></h5>-->
                    <!--<p>-->

                    <!--<br/>-->
                    <!--</p>-->
                    <h5>Biography</h5>
                    <p>
                        Marjan Ghazvininejad is a Research Scientist in Facebook AI Research. She is interested in text representation, language generation, and machine translation. Her recent focus has been on new approaches for modeling and training of these systems to generate high quality, coherent, and creative text. She received her PhD in 2018 from the University of Southern California under the supervision of Kevin Knight.
                    </p>
                </div>
            </div>
        </div>

        <br/>

        <div id="liang" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Liang Huang</h4>
                    <hr>
                    <h5>Linear-Time Parsing Meets RNA Folding</h5>
                    <p>
                        Predicting the secondary structure of an ribonucleic acid (RNA) sequence is useful in many applications. Existing algorithms [based on dynamic programming] suffer from a major limitation: their runtimes scale cubically with the RNA length, and this slowness limits their use in genome-wide applications. <br/><br/>

We first present a novel alternative O(n^3)-time dynamic programming algorithm for RNA folding that is amenable to heuristics that make it run in O(n) time and O(n) space, while producing a high-quality approximation to the optimal solution. Inspired by the authorâ€™s earlier work on incremental parsing for context-free grammars in computational linguistics, our alternative dynamic programming algorithm scans the sequence in a left-to-right (5'-to-3') direction rather than in a bottom-up fashion, which allows us to employ the effective beam pruning heuristic. Our work, though inexact, is the first RNA folding algorithm to achieve linear runtime (and linear space) without imposing constraints on the output structure. Surprisingly, our approximate search results in even higher overall accuracy on a diverse database of sequences with known structures. More interestingly, it leads to significantly more accurate predictions on the longest sequence families in that database (16S and 23S Ribosomal RNAs), as well as improved accuracies for long-range base pairs (500+ nucleotides apart), both of which are well known to be challenging for the current models.
                    </p>
                    <h5>Biography</h5>
                    <p>
Liang Huang is currently an Assistant Professor of EECS at Oregon State University and Principal Scientist at Baidu Research USA. Before that he was Assistant Professor for three years at the City University of New York (CUNY) and a part-time Research Scientist with IBM's Watson Group. He graduated in 2008 from Penn and has worked as a Research Scientist at Google and a Research Assistant Professor at USC/ISI. Most of his work develops fast algorithms and provable theory to speedup large-scale natural language processing, structured machine learning, and computational structural biology. He has received a Best Paper Award at ACL 2008, a Best Paper Honorable Mention at EMNLP 2016, several best paper nominations (ACL 2007, EMNLP 2008, and ACL 2010), two Google Faculty Research Awards (2010 and 2013), a Yahoo! Faculty Research Award (2015), and a University Teaching Prize at Penn (2005). His research has been supported by DARPA, NSF, Google, and Yahoo. He also co-authored a best-selling textbook in China on algorithms for programming contests.
                    </p>
                </div>
            </div>
        </div>

        <br/>

        <div id="kevin" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Kevin Knight</h4>
                    <hr>
                    <h5>NLP in Hollywood?</h5>
                    <p>
                    Is there a role for recurrent neural networks in the making of Hollywood movies?  I'll answer in the affirmative, and give a few examples.
                    </p>
                    <h5>Biography</h5>
                    <p>
                    Kevin Knight is Chief Scientist for Natural Language Processing at Didi Chuxing.  He received a PhD in computer science from Carnegie Mellon University and a bachelor's degree from Harvard University.  Dr. Knight's research interests include human-machine communication, machine translation, language generation, automata theory, and decipherment.  He has co-authored over 150 research paper on natural language processing, as well as the widely-adopted textbook "Artificial Intelligence" (McGraw-Hill).  In 2001, he co-founded Language Weaver, Inc., a machine translation company acquired by SDL plc in 2010.  Dr. Knight served as President of the Association for Computational Linguistics (ACL) in 2011, as General Chair for ACL in 2005, and as General Chair for the North American ACL in 2016.  He is a Fellow of the ACL, USC/ISI, and AAAI.
                    </p>
                </div>
            </div>
        </div>

        <br/>

        <div id="ndapa" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Ndapa Nakashole</h4>
                    <hr>
                    <!--<h5></h5>-->
                    <!--<p>-->
                    <!--</p>-->
                    <h5>Biography</h5>
                    <p>
                    Ndapa Nakashole is an Assistant Professor at the University of California, San Diego, where she has been teaching and doing research on statistical natural language language processing since 2017. <br/>Before that she did a postdoc at the machine learning department at Carnegie Mellon University. <br/>She obtained her PhD from Saarland University and  the Max Planck Institute for Informatics. <br/>She completed undergraduate studies in Computer Science at the University of Cape Town, South Africa.
                    </p>
                </div>
            </div>
        </div>

        <br/>

        <div id="sameer" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Sameer Singh</h4>
                    <hr>
                    <!--<h5></h5>-->
                    <!--<p>-->
                    <!--</p>-->
                    <h5>Biography</h5>
                    <p>
                    Sameer Singh is an Assistant Professor of Computer Science at the University of California, Irvine. He is working on large-scale and interpretable machine learning applied to natural language processing. Sameer was a Postdoctoral Research Associate at the University of Washington and received his PhD from the University of Massachusetts, Amherst, during which he also worked at Microsoft Research, Google Research, and Yahoo! Labs. His group has received funding from Allen Institute for AI, NSF, DARPA, Adobe Research, and FICO, and was selected as a DARPA Riser in 2015. Sameer has published extensively at top-tier machine learning and natural language processing conferences.
                    </p>
                </div>
            </div>
        </div>

        <br/>

        <div id="luke" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Luke Zettlemoyer</h4>
                    <hr>
                    <!--<h5></h5>-->
                    <!--<p>-->
                    <!--</p>-->
                    <h5>Biography</h5>
                    <p>
                    Luke Zettlemoyer is an Associate Professor in the Paul G. Allen School of Computer Science & Engineering at the University of Washington, and a Research Scientist at Facebook. His research focuses on empirical methods for natural language understanding, and involves designing machine learning algorithms and building large datasets. Honors include multiple paper awards, a PECASE award, and an Allen Distinguished Investigator Award. Luke received his PhD from MIT and was a postdoc at the University of Edinburgh.
                    </p>
                </div>
            </div>
        </div>

        <br/>



        <!--<hr>-->

        <div class="container footer">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <p align="left">
                        Copyright &copy; SoCal NLP Symposium 2019
                    </p>
                </div>
            </div>
        </div>
    </body>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script>window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')</script>
    <script src="js/popper.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
</html>
